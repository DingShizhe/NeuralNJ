num_epoch: 1000
num_episodes: 10
num_episodes_baseline: 50
# num_episodes_baseline: 5
# lr: 0.01
lr: 0.001
clip_value: 0.1
entropy_reg_strength: 0.2
# entropy_reg_strength: 0.05
risk_epsilon: 0.5

infer_opt: "Reinforced"

# replay_buffer_size: 48
# replay_buffer_size: 16
# replay_buffer_size: 2
# replay_buffer_sample_size: 2
# replay_buffer_sample_size: 24

# replay_buffer_score_bound: 20

# summary_name: "G_l_1000_n_100_0.0_0.05_0__temp2.0"
# summary_name: "G_l_1024_n_20_0.0_0.04_0_train20_30_patch4_rbsample16_bs32"
# summary_path: "tb_opt_RL_finetune_dataTaxa20"
# summary_path: "NULL"
# summary_path: "tb_step_loss"
# checkpoint_path: "policy_checkpoints"


instance_path: "datasete_real/Mix_filter_validation_1000"



reload_checkpoint_path: "checkpoints/20240509-103334train_realMix_hGlobal_scoremean_Highway_FuseAttnXRest_real_NoNorm_hgWoMeanWoMLP_EncAttnl2_sharedAGG_BalancedELU_dim32head2_lr0.001_woclip_decay0.96_ratio1_margin0.5_patch2_bs4_RawTopo_BtmTopTraj/checkpoint_64.pt"

# pretrained model with patch size = 2

env:
  # batch_size: 4
  batch_size: 1
  # batch_size: 128
  # BATCH_SIZE: 8
  sequence_type: DNA_WITH_GAP

model:
  vocab_size: 4
  patch_size: 2
  fixed_length: 1024
  embed_dim: 32
  encoder_attn_layers: 2
  num_enc_heads: 2